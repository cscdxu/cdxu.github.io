**argparse.ArgumentParser**

https://xxxpt.blog.csdn.net/article/details/106517985?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link

 

**random.randint(参数1，参数2)**

- 参数1、参数2必须是**整数**
- 函数返回参数1和参数2之间的**任意整数**

##### **random.seed()**

当seed()没有参数时，每次生成的随机数是不一样的，而当seed()有相同参数时，每次生成的随机数是一样的，同时选择不同的参数生成的随机数也不一样



**调整学习率**

https://blog.csdn.net/qyhaill/article/details/103043637

##### pytorch中.to(device) 和.cuda()的区别说明

.to(device) 可以指定CPU 或者GPU

.cuda() 只能指定GPU

##### optimizer.step()和scheduler.step()

https://blog.csdn.net/qq_20622615/article/details/83150963

##### transpose函数

https://www.cnblogs.com/caizhou520/p/11227986.html

##### pytorch梯度置零反向传播

https://blog.csdn.net/PanYHHH/article/details/107361827

##### Python os.makedirs try 以及 raise

https://blog.csdn.net/jyl1999xxxx/article/details/51848240

##### pytorch中load和load_state_dict区别

https://yonggie.blog.csdn.net/article/details/105882087?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link

